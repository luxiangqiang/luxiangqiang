---
title:  数据分析之爬虫【基本流程】
categories:
- python
- 数据分析
tags:
- python
- 数据分析
---

![](/images/爬虫基本流程.png)

本篇文章教你数据分析爬虫的基本流程！

<!--more-->

### 一、爬虫的基本流程

> 三个基本流程：
>
> - 打开网页: Request 访问网页，得到服务器返回的数据，包括 HTML 和 JSON 数据。
> - 提取数据: 针对 HTML 使用 XPath 元素定位；针对 JSON 使用 JSON 进行解析。
> - 保存数据：使用 Pandas 保存数据，最后导出 XSL 或 CSV 文件。



#### 1、Request 访问页面

> Request 是 Python 的 HTTP 的客户端库，两种访问方式 GET 和 POST 。请求回来的数据可以通过 `text` 或 `content` 来获取 HTML 的正文。

```python
// get 方式
r = requests.get('http://www.douban.com')
// post 方式
r = requests.post('http://xxx.com', data = {'key':'value'})
```



#### 2、XPath 定位

> XPath 是 XML 的路径语言，通过元素和属性进行导航，定位位置。
>
> 1）XPath 有 100 多个内置函数进行快速的定位。
>
> 2）XPath 需要借助一个解析库 lxml 。例如:

```python
// 得到 HTML 的所有列表项目
from lxml import etree
html = etree.HTML(html)
result = html.xpath('//li')
```

![img](https://static001.geekbang.org/resource/image/3b/ea/3bcb311361c76bfbeb90d360b21195ea.jpg)



#### 3、JSON 对象

> Python 中有 JSON 库，可以将 Python 对象和 JSON 对象相互转换。

![img](https://static001.geekbang.org/resource/image/9a/43/9a6d6564a64cf2b1c256265eea78c543.png)



#### 4、使用 JSON 数据爬取实战

> 抓取的页面时动态页面，需要关注 XHR 数据，动态页面是通过原生的 XHR 数据对象发送 HTTP 请求，得到服务器返回的值，在进行处理。（使用谷歌开发工具可以查看）



###### ▉ 导包

```python
# coding:utf-8
import requests
import json
```



###### ▉ 查看 XHR 请求的页数

```python
# range(开始，结束，步长)  
for i in range(0,23287,20):
    # XHR 请求的路径
    url = 'https://www.douban.com/j/search_photo?q=' + query + '&limit=20&start=' + str(i)
```



###### ▉ 进行 XHR 请求

```python
# 获取服务器返回的文本
html = requests.get(url).text
```



###### ▉ 将 JSON 对象转化为 Python 对象进行解析

```python
# 将 JSON 转化为 Python 对象
response = json.loads(html,encoding='utf-8')
```



###### ▉ 循环遍历出内容

```python
# images: [{src: "https://img3.doubanio.com/view/photo/thumb/public/p637714342.jpg", author: "華生",…},…]
# 获取内容数组
response['images']
# 获取数组中的每个对象
for image in response['images']
# 获取每个对象中的值
image['src']
```



###### ▉ 下载图片

```python
def download(src,id):
    # 设置路径和图片命名
    dir = './' + str(id) + '.jpg'
    try:
        # timeout 设置爬虫超时操作
        pic = requests.get(src,timeout = 10)
        # 内置函数 open 用于打开文件(wb 二进制文件只写入)
        fp = open(dir,'wb')
        # 以二进制方式写入本地文件
        fp.write(pic.content)
        fp.close()
    except requests.exceptions.ConnectionError:
        print('图片无法下载')
```



#### 5、使用 XPath 爬取数据

> 网页除了用  XHR 做请求，也会用 JS 做请求，如果用到 JS 做请求，那么我们就用 XPath 做解析。用 XPath 做解析必须 JS 请求后接受到整个页面之后，才能进行解析。
>
> 1）快速定位 XPath 的方法就是使用谷歌插件 XPath Helper 使用快捷键 Ctrl + Shift + X ,直接定位你想要的元素。
>
> 2）使用 lxml 库来进行对获取的网页进行解析。



##### 1、Selenium 模拟测试工具

> 因为 XPath 的使用必须在页面加载完成才可以，所以使用 Request 获取页面的 HTML 时候，发现 XPath 并不存在，所以必须借助 Selenium 模拟工具（模拟用户操作页面的工具）。
>
> 1）必须下载 Driver 执行程序才能正常打开浏览器。



##### 2、代码实现

###### ▉ 加载浏览器程序

```python
browser = webdriver.Chrome('C:/Program Files (x86)/Google/Chrome/Application/chromedriver.exe')
```



###### ▉ 打开指定网址

```python
// 尽情请求
browser.get(url)
```



###### ▉  获取网页源代码

```python
// 获取打开网页的源代码
browser.page_source
// 转化为可以被 lxml 解析的对象
html = etree.HTML(browser.page_source)
```



###### ▉  获取到 XPath 匹配的元素

```python
src_xpath = "//div[@class='result']/div[@class='pic']/a[@class='nbg']/img/@src"
srcs = html.xpath(src_xpath)
```



###### ▉  遍历获取数据

```python
# zip 将对象中对应的元素打包成元组
for src,title in zip(srcs,titles):
    print(src)
    download(src,title.text)
```



















